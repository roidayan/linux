From: Vladimir Sokolovsky <vlad@mellanox.com>
Subject: [PATCH] BACKPORT: mlx5

Signed-off-by: Vladimir Sokolovsky <vlad@mellanox.com>
---
 drivers/infiniband/hw/mlx5/mr.c                    |    7 +++
 drivers/net/ethernet/mellanox/mlx5/core/cmd.c      |   26 ++++++++++++
 drivers/net/ethernet/mellanox/mlx5/core/en.h       |   24 +++++++++++
 .../net/ethernet/mellanox/mlx5/core/en_ethtool.c   |    2 +
 .../ethernet/mellanox/mlx5/core/en_flow_table.c    |   44 ++++++++++++++++++++
 drivers/net/ethernet/mellanox/mlx5/core/en_main.c  |   37 ++++++++++++++++
 drivers/net/ethernet/mellanox/mlx5/core/en_rx.c    |    8 ++++
 drivers/net/ethernet/mellanox/mlx5/core/en_tx.c    |   22 ++++++++++
 drivers/net/ethernet/mellanox/mlx5/core/main.c     |   23 ++++++++++
 include/linux/compat-3.5.h                         |   14 ++++++
 include/linux/mlx5/driver.h                        |    5 ++
 11 files changed, 212 insertions(+), 0 deletions(-)

diff --git a/drivers/infiniband/hw/mlx5/mr.c b/drivers/infiniband/hw/mlx5/mr.c
index xxxxxxx..xxxxxxx xxxxxx
--- a/drivers/infiniband/hw/mlx5/mr.c
+++ b/drivers/infiniband/hw/mlx5/mr.c
@@ -38,6 +38,9 @@
 #include <linux/delay.h>
 #include <linux/device.h>
 #include <linux/sysfs.h>
+#ifndef ARCH_KMALLOC_MINALIGN
+#include <linux/crypto.h>
+#endif
 #include <rdma/ib_umem.h>
 #include <rdma/ib_umem_odp.h>
 #include <rdma/ib_verbs.h>
@@ -1954,7 +1957,11 @@ mlx5_ib_alloc_indir_reg_list(struct ib_device *device,
 	}
 
 	dsize = sizeof(*mirl->klms) * max_indir_list_len;
+#ifdef ARCH_KMALLOC_MINALIGN
 	dsize += max_t(int, MLX5_UMR_ALIGN - ARCH_KMALLOC_MINALIGN, 0);
+#else
+	dsize += max_t(int, MLX5_UMR_ALIGN - CRYPTO_MINALIGN, 0);
+#endif
 	mirl->mapped_ilist = kzalloc(dsize, GFP_KERNEL);
 	if (!mirl->mapped_ilist) {
 		err = -ENOMEM;
diff --git a/drivers/net/ethernet/mellanox/mlx5/core/cmd.c b/drivers/net/ethernet/mellanox/mlx5/core/cmd.c
index xxxxxxx..xxxxxxx xxxxxx
--- a/drivers/net/ethernet/mellanox/mlx5/core/cmd.c
+++ b/drivers/net/ethernet/mellanox/mlx5/core/cmd.c
@@ -583,7 +583,11 @@ static void cmd_work_handler(struct work_struct *work)
 	lay->status_own = CMD_OWNER_HW;
 	set_signature(ent, !cmd->checksum_disabled);
 	dump_command(dev, ent, 1);
+#ifdef HAVE_KTIME_GET_NS
 	ent->ts1 = ktime_get_ns();
+#else
+	ktime_get_ts(&ent->ts1);
+#endif
 
 	/* ring doorbell after the descriptor is valid */
 	mlx5_core_dbg(dev, "writing 0x%x to command doorbell\n", 1 << ent->idx);
@@ -674,6 +678,9 @@ static int mlx5_cmd_invoke(struct mlx5_core_dev *dev, struct mlx5_cmd_msg *in,
 	struct mlx5_cmd *cmd = &dev->cmd;
 	struct mlx5_cmd_work_ent *ent;
 	struct mlx5_cmd_stats *stats;
+#ifndef HAVE_KTIME_GET_NS
+	ktime_t t1, t2, delta;
+#endif
 	int err = 0;
 	s64 ds;
 	u16 op;
@@ -711,7 +718,14 @@ static int mlx5_cmd_invoke(struct mlx5_core_dev *dev, struct mlx5_cmd_msg *in,
 		if (err == -ETIMEDOUT)
 			goto out;
 
+#ifdef HAVE_KTIME_GET_NS
 		ds = ent->ts2 - ent->ts1;
+#else
+		t1 = timespec_to_ktime(ent->ts1);
+		t2 = timespec_to_ktime(ent->ts2);
+		delta = ktime_sub(t2, t1);
+		ds = ktime_to_ns(delta);
+#endif
 		op = be16_to_cpu(((struct mlx5_inbox_hdr *)in->first.data)->opcode);
 		if (op < ARRAY_SIZE(cmd->stats)) {
 			stats = &cmd->stats[op];
@@ -1175,6 +1189,7 @@ void mlx5_cmd_comp_handler(struct mlx5_core_dev *dev, unsigned long vector)
 	void *context;
 	int err;
 	int i;
+	ktime_t t1, t2, delta;
 	s64 ds;
 	struct mlx5_cmd_stats *stats;
 	unsigned long flags;
@@ -1188,7 +1203,11 @@ void mlx5_cmd_comp_handler(struct mlx5_core_dev *dev, unsigned long vector)
 				sem = &cmd->pages_sem;
 			else
 				sem = &cmd->sem;
+#ifdef HAVE_KTIME_GET_NS
 			ent->ts2 = ktime_get_ns();
+#else
+			ktime_get_ts(&ent->ts2);
+#endif
 			memcpy(ent->out->first.data, ent->lay->out, sizeof(ent->lay->out));
 			dump_command(dev, ent, 0);
 			if (!ent->ret) {
@@ -1202,7 +1221,14 @@ void mlx5_cmd_comp_handler(struct mlx5_core_dev *dev, unsigned long vector)
 			}
 			free_ent(cmd, ent->idx);
 			if (ent->callback) {
+#ifdef HAVE_KTIME_GET_NS
 				ds = ent->ts2 - ent->ts1;
+#else
+				t1 = timespec_to_ktime(ent->ts1);
+				t2 = timespec_to_ktime(ent->ts2);
+				delta = ktime_sub(t2, t1);
+				ds = ktime_to_ns(delta);
+#endif
 				if (ent->op < ARRAY_SIZE(cmd->stats)) {
 					stats = &cmd->stats[ent->op];
 					spin_lock_irqsave(&stats->lock, flags);
diff --git a/drivers/net/ethernet/mellanox/mlx5/core/en.h b/drivers/net/ethernet/mellanox/mlx5/core/en.h
index xxxxxxx..xxxxxxx xxxxxx
--- a/drivers/net/ethernet/mellanox/mlx5/core/en.h
+++ b/drivers/net/ethernet/mellanox/mlx5/core/en.h
@@ -404,6 +404,9 @@ struct mlx5e_priv {
 	struct mlx5_core_dev      *mdev;
 	struct net_device         *netdev;
 	struct mlx5e_stats         stats;
+#ifndef HAVE_NDO_GET_STATS64
+	struct net_device_stats	   netdev_stats;
+#endif
 };
 
 #define MLX5E_NET_IP_ALIGN 2
@@ -450,8 +453,17 @@ enum mlx5e_link_mode {
 
 #define MLX5E_PROT_MASK(link_mode) (1 << link_mode)
 
+#if defined(NDO_SELECT_QUEUE_HAS_ACCEL_PRIV) || defined(HAVE_SELECT_QUEUE_FALLBACK_T)
 u16 mlx5e_select_queue(struct net_device *dev, struct sk_buff *skb,
+#ifdef HAVE_SELECT_QUEUE_FALLBACK_T
 		       void *accel_priv, select_queue_fallback_t fallback);
+#else
+		       select_queue void *accel_priv);
+#endif
+#else /* NDO_SELECT_QUEUE_HAS_ACCEL_PRIV || HAVE_SELECT_QUEUE_FALLBACK_T */
+u16 mlx5e_select_queue(struct net_device *dev, struct sk_buff *skb);
+#endif
+
 netdev_tx_t mlx5e_xmit(struct sk_buff *skb, struct net_device *dev);
 netdev_tx_t mlx5e_xmit_multi_tc(struct sk_buff *skb, struct net_device *dev);
 
@@ -471,10 +483,22 @@ void mlx5e_init_eth_addr(struct mlx5e_priv *priv);
 void mlx5e_set_rx_mode_core(struct mlx5e_priv *priv);
 void mlx5e_set_rx_mode_work(struct work_struct *work);
 
+#if (LINUX_VERSION_CODE >= KERNEL_VERSION(3,10,0))
 int mlx5e_vlan_rx_add_vid(struct net_device *dev, __always_unused __be16 proto,
 			  u16 vid);
+#elif (LINUX_VERSION_CODE >= KERNEL_VERSION(3,3,0))
+int mlx5e_vlan_rx_add_vid(struct net_device *dev, u16 vid);
+#else
+void mlx5e_vlan_rx_add_vid(struct net_device *dev, u16 vid);
+#endif
+#if (LINUX_VERSION_CODE >= KERNEL_VERSION(3,10,0))
 int mlx5e_vlan_rx_kill_vid(struct net_device *dev, __always_unused __be16 proto,
 			   u16 vid);
+#elif (LINUX_VERSION_CODE >= KERNEL_VERSION(3,3,0))
+int mlx5e_vlan_rx_kill_vid(struct net_device *dev, u16 vid);
+#else
+void mlx5e_vlan_rx_kill_vid(struct net_device *dev, u16 vid);
+#endif
 void mlx5e_enable_vlan_filter(struct mlx5e_priv *priv);
 void mlx5e_disable_vlan_filter(struct mlx5e_priv *priv);
 int mlx5e_add_all_vlan_rules(struct mlx5e_priv *priv);
diff --git a/drivers/net/ethernet/mellanox/mlx5/core/en_ethtool.c b/drivers/net/ethernet/mellanox/mlx5/core/en_ethtool.c
index xxxxxxx..xxxxxxx xxxxxx
--- a/drivers/net/ethernet/mellanox/mlx5/core/en_ethtool.c
+++ b/drivers/net/ethernet/mellanox/mlx5/core/en_ethtool.c
@@ -737,8 +737,10 @@ const struct ethtool_ops mlx5e_ethtool_ops = {
 	.get_ethtool_stats = mlx5e_get_ethtool_stats,
 	.get_ringparam     = mlx5e_get_ringparam,
 	.set_ringparam     = mlx5e_set_ringparam,
+#ifdef HAVE_GET_SET_CHANNELS
 	.get_channels      = mlx5e_get_channels,
 	.set_channels      = mlx5e_set_channels,
+#endif
 	.get_coalesce      = mlx5e_get_coalesce,
 	.set_coalesce      = mlx5e_set_coalesce,
 	.get_settings      = mlx5e_get_settings,
diff --git a/drivers/net/ethernet/mellanox/mlx5/core/en_flow_table.c b/drivers/net/ethernet/mellanox/mlx5/core/en_flow_table.c
index xxxxxxx..xxxxxxx xxxxxx
--- a/drivers/net/ethernet/mellanox/mlx5/core/en_flow_table.c
+++ b/drivers/net/ethernet/mellanox/mlx5/core/en_flow_table.c
@@ -72,8 +72,15 @@ static void mlx5e_add_eth_addr_to_hash(struct hlist_head *hash, u8 *addr)
 	struct mlx5e_eth_addr_hash_node *hn;
 	int ix = mlx5e_hash_eth_addr(addr);
 	int found = 0;
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(3,9,0))
+	struct hlist_node *pos;
+#endif
 
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(3,9,0))
+	hlist_for_each_entry(hn, pos, &hash[ix], hlist)
+#else
 	hlist_for_each_entry(hn, &hash[ix], hlist)
+#endif
 		if (ether_addr_equal_64bits(hn->ai.addr, addr)) {
 			found = 1;
 			break;
@@ -520,8 +527,14 @@ void mlx5e_disable_vlan_filter(struct mlx5e_priv *priv)
 	mutex_unlock(&priv->state_lock);
 }
 
+#if (LINUX_VERSION_CODE >= KERNEL_VERSION(3,10,0))
 int mlx5e_vlan_rx_add_vid(struct net_device *dev, __always_unused __be16 proto,
 			  u16 vid)
+#elif (LINUX_VERSION_CODE >= KERNEL_VERSION(3,3,0))
+int mlx5e_vlan_rx_add_vid(struct net_device *dev, u16 vid)
+#else
+void mlx5e_vlan_rx_add_vid(struct net_device *dev, u16 vid)
+#endif
 {
 	struct mlx5e_priv *priv = netdev_priv(dev);
 	int err = 0;
@@ -535,11 +548,19 @@ int mlx5e_vlan_rx_add_vid(struct net_device *dev, __always_unused __be16 proto,
 
 	mutex_unlock(&priv->state_lock);
 
+#if (LINUX_VERSION_CODE >= KERNEL_VERSION(3,3,0))
 	return err;
+#endif
 }
 
+#if (LINUX_VERSION_CODE >= KERNEL_VERSION(3,10,0))
 int mlx5e_vlan_rx_kill_vid(struct net_device *dev, __always_unused __be16 proto,
 			   u16 vid)
+#elif (LINUX_VERSION_CODE >= KERNEL_VERSION(3,3,0))
+int mlx5e_vlan_rx_kill_vid(struct net_device *dev, u16 vid)
+#else
+void mlx5e_vlan_rx_kill_vid(struct net_device *dev, u16 vid)
+#endif
 {
 	struct mlx5e_priv *priv = netdev_priv(dev);
 
@@ -551,7 +572,9 @@ int mlx5e_vlan_rx_kill_vid(struct net_device *dev, __always_unused __be16 proto,
 
 	mutex_unlock(&priv->state_lock);
 
+#if (LINUX_VERSION_CODE >= KERNEL_VERSION(3,3,0))
 	return 0;
+#endif
 }
 
 int mlx5e_add_all_vlan_rules(struct mlx5e_priv *priv)
@@ -593,9 +616,15 @@ void mlx5e_del_all_vlan_rules(struct mlx5e_priv *priv)
 		mlx5e_del_vlan_rule(priv, MLX5E_VLAN_RULE_TYPE_MATCH_VID, vid);
 }
 
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(3,9,0))
+#define mlx5e_for_each_hash_node(hn, tmp, hash, i) \
+	for (i = 0; i < MLX5E_ETH_ADDR_HASH_SIZE; i++) \
+		hlist_for_each_entry_safe(hn, n, tmp, &hash[i], hlist)
+#else
 #define mlx5e_for_each_hash_node(hn, tmp, hash, i) \
 	for (i = 0; i < MLX5E_ETH_ADDR_HASH_SIZE; i++) \
 		hlist_for_each_entry_safe(hn, tmp, &hash[i], hlist)
+#endif
 
 static void mlx5e_execute_action(struct mlx5e_priv *priv,
 				 struct mlx5e_eth_addr_hash_node *hn)
@@ -617,6 +646,9 @@ static void mlx5e_sync_netdev_addr(struct mlx5e_priv *priv)
 {
 	struct net_device *netdev = priv->netdev;
 	struct netdev_hw_addr *ha;
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2,6,35))
+	struct dev_mc_list *mclist;
+#endif
 
 	netif_addr_lock_bh(netdev);
 
@@ -626,7 +658,11 @@ static void mlx5e_sync_netdev_addr(struct mlx5e_priv *priv)
 	netdev_for_each_uc_addr(ha, netdev)
 		mlx5e_add_eth_addr_to_hash(priv->eth_addr.netdev_uc, ha->addr);
 
+#if (LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,35))
 	netdev_for_each_mc_addr(ha, netdev)
+#else
+	for (mclist = netdev->mc_list; mclist; mclist = mclist->next)
+#endif
 		mlx5e_add_eth_addr_to_hash(priv->eth_addr.netdev_mc, ha->addr);
 
 	netif_addr_unlock_bh(netdev);
@@ -635,7 +671,11 @@ static void mlx5e_sync_netdev_addr(struct mlx5e_priv *priv)
 static void mlx5e_apply_netdev_addr(struct mlx5e_priv *priv)
 {
 	struct mlx5e_eth_addr_hash_node *hn;
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(3,9,0))
+	struct hlist_node *n, *tmp;
+#else
 	struct hlist_node *tmp;
+#endif
 	int i;
 
 	mlx5e_for_each_hash_node(hn, tmp, priv->eth_addr.netdev_uc, i)
@@ -648,7 +688,11 @@ static void mlx5e_apply_netdev_addr(struct mlx5e_priv *priv)
 static void mlx5e_handle_netdev_addr(struct mlx5e_priv *priv)
 {
 	struct mlx5e_eth_addr_hash_node *hn;
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(3,9,0))
+	struct hlist_node *n, *tmp;
+#else
 	struct hlist_node *tmp;
+#endif
 	int i;
 
 	mlx5e_for_each_hash_node(hn, tmp, priv->eth_addr.netdev_uc, i)
diff --git a/drivers/net/ethernet/mellanox/mlx5/core/en_main.c b/drivers/net/ethernet/mellanox/mlx5/core/en_main.c
index xxxxxxx..xxxxxxx xxxxxx
--- a/drivers/net/ethernet/mellanox/mlx5/core/en_main.c
+++ b/drivers/net/ethernet/mellanox/mlx5/core/en_main.c
@@ -1233,6 +1233,9 @@ static void mlx5e_close_rqt(struct mlx5e_priv *priv)
 static void mlx5e_build_tir_ctx(struct mlx5e_priv *priv, u32 *tirc, int tt)
 {
 	void *hfso = MLX5_ADDR_OF(tirc, tirc, rx_hash_field_selector_outer);
+#ifndef HAVE_NETDEV_RSS_KEY_FILL
+	__be32 *hkey;
+#endif
 
 #define ROUGH_MAX_L2_L3_HDR_SZ 256
 
@@ -1272,10 +1275,24 @@ static void mlx5e_build_tir_ctx(struct mlx5e_priv *priv, u32 *tirc, int tt)
 		MLX5_SET(tirc, tirc, rx_hash_fn,
 			 MLX5_TIRC_RX_HASH_FN_HASH_TOEPLITZ);
 		MLX5_SET(tirc, tirc, rx_hash_symmetric, 1);
+#ifdef HAVE_NETDEV_RSS_KEY_FILL
 		netdev_rss_key_fill(MLX5_ADDR_OF(tirc, tirc,
 						 rx_hash_toeplitz_key),
 				    MLX5_FLD_SZ_BYTES(tirc,
 						      rx_hash_toeplitz_key));
+#else
+		hkey = (__be32 *)MLX5_ADDR_OF(tirc, tirc, rx_hash_toeplitz_key);
+		hkey[0] = cpu_to_be32(0xD181C62C);
+		hkey[1] = cpu_to_be32(0xF7F4DB5B);
+		hkey[2] = cpu_to_be32(0x1983A2FC);
+		hkey[3] = cpu_to_be32(0x943E1ADB);
+		hkey[4] = cpu_to_be32(0xD9389E6B);
+		hkey[5] = cpu_to_be32(0xD1039C2C);
+		hkey[6] = cpu_to_be32(0xA74499AD);
+		hkey[7] = cpu_to_be32(0x593D56D9);
+		hkey[8] = cpu_to_be32(0xF3253C06);
+		hkey[9] = cpu_to_be32(0x2ADC1FFC);
+#endif
 		break;
 	}
 
@@ -1512,12 +1529,20 @@ static int mlx5e_close(struct net_device *netdev)
 	return err;
 }
 
+#ifdef HAVE_NDO_GET_STATS64
 static struct rtnl_link_stats64 *
 mlx5e_get_stats(struct net_device *dev, struct rtnl_link_stats64 *stats)
+#else
+static struct net_device_stats *mlx5e_get_stats(struct net_device *dev)
+#endif
 {
 	struct mlx5e_priv *priv = netdev_priv(dev);
 	struct mlx5e_vport_stats *vstats = &priv->stats.vport;
 
+#ifndef HAVE_NDO_GET_STATS64
+	struct net_device_stats *stats = &priv->netdev_stats;
+#endif
+
 	mlx5e_update_stats(priv);
 
 	stats->rx_packets = vstats->rx_packets;
@@ -1580,12 +1605,19 @@ static struct net_device_ops mlx5e_netdev_ops = {
 	.ndo_open                = mlx5e_open,
 	.ndo_stop                = mlx5e_close,
 	.ndo_start_xmit          = mlx5e_xmit,
+#ifdef HAVE_NDO_GET_STATS64
 	.ndo_get_stats64         = mlx5e_get_stats,
+#else
+	.ndo_get_stats           = mlx5e_get_stats,
+#endif
 	.ndo_set_rx_mode         = mlx5e_set_rx_mode,
 	.ndo_set_mac_address     = mlx5e_set_mac,
 	.ndo_vlan_rx_add_vid	 = mlx5e_vlan_rx_add_vid,
 	.ndo_vlan_rx_kill_vid	 = mlx5e_vlan_rx_kill_vid,
+#ifdef HAVE_NDO_SET_FEATURES
 	.ndo_set_features        = mlx5e_set_features,
+//TODO: use RH ext ops struct if available like mlx4 do
+#endif
 };
 
 static int mlx5e_check_required_hca_cap(struct mlx5_core_dev *mdev)
@@ -1698,15 +1730,20 @@ static void mlx5e_build_netdev(struct net_device *netdev)
 	if (!!MLX5_CAP_ETH(mdev, lro_cap))
 		netdev->vlan_features    |= NETIF_F_LRO;
 
+#ifdef HAVE_NETDEV_HW_FEATURES
 	netdev->hw_features       = netdev->vlan_features;
 	netdev->hw_features      |= NETIF_F_HW_VLAN_CTAG_TX;
 	netdev->hw_features      |= NETIF_F_HW_VLAN_CTAG_RX;
 	netdev->hw_features      |= NETIF_F_HW_VLAN_CTAG_FILTER;
 
 	netdev->features          = netdev->hw_features & ~NETIF_F_LRO;
+// TODO: else
+#endif
 	netdev->features         |= NETIF_F_HIGHDMA;
 
+#if (LINUX_VERSION_CODE >= KERNEL_VERSION(3,2,0))
 	netdev->priv_flags       |= IFF_UNICAST_FLT;
+#endif
 
 	mlx5e_set_netdev_dev_addr(netdev);
 }
diff --git a/drivers/net/ethernet/mellanox/mlx5/core/en_rx.c b/drivers/net/ethernet/mellanox/mlx5/core/en_rx.c
index xxxxxxx..xxxxxxx xxxxxx
--- a/drivers/net/ethernet/mellanox/mlx5/core/en_rx.c
+++ b/drivers/net/ethernet/mellanox/mlx5/core/en_rx.c
@@ -147,11 +147,15 @@ static void mlx5e_lro_update_hdr(struct sk_buff *skb, struct mlx5_cqe64 *cqe)
 static inline void mlx5e_skb_set_hash(struct mlx5_cqe64 *cqe,
 				      struct sk_buff *skb)
 {
+#ifdef HAVE_SKB_SET_HASH
 	u8 cht = cqe->rss_hash_type;
 	int ht = (cht & CQE_RSS_HTYPE_L4) ? PKT_HASH_TYPE_L4 :
 		 (cht & CQE_RSS_HTYPE_IP) ? PKT_HASH_TYPE_L3 :
 					    PKT_HASH_TYPE_NONE;
 	skb_set_hash(skb, be32_to_cpu(cqe->rss_hash_result), ht);
+#else
+	skb->rxhash = be32_to_cpu(cqe->rss_hash_result);
+#endif
 }
 
 static inline void mlx5e_build_rx_skb(struct mlx5_cqe64 *cqe,
@@ -190,8 +194,12 @@ static inline void mlx5e_build_rx_skb(struct mlx5_cqe64 *cqe,
 		mlx5e_skb_set_hash(cqe, skb);
 
 	if (cqe_has_vlan(cqe))
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(3,10,0))
+		__vlan_hwaccel_put_tag(skb, be16_to_cpu(cqe->vlan_info));
+#else
 		__vlan_hwaccel_put_tag(skb, htons(ETH_P_8021Q),
 				       be16_to_cpu(cqe->vlan_info));
+#endif
 }
 
 bool mlx5e_poll_rx_cq(struct mlx5e_cq *cq, int budget)
diff --git a/drivers/net/ethernet/mellanox/mlx5/core/en_tx.c b/drivers/net/ethernet/mellanox/mlx5/core/en_tx.c
index xxxxxxx..xxxxxxx xxxxxx
--- a/drivers/net/ethernet/mellanox/mlx5/core/en_tx.c
+++ b/drivers/net/ethernet/mellanox/mlx5/core/en_tx.c
@@ -69,8 +69,20 @@ static inline void mlx5e_dma_get(struct mlx5e_sq *sq, u32 i, dma_addr_t *addr,
 	*size = sq->dma_fifo[i & sq->dma_fifo_mask].size;
 }
 
+#ifndef HAVE_SELECT_QUEUE_FALLBACK_T
+#define fallback(dev, skb) __netdev_pick_tx(dev, skb)
+#endif
+
+#if defined(NDO_SELECT_QUEUE_HAS_ACCEL_PRIV) || defined(HAVE_SELECT_QUEUE_FALLBACK_T)
 u16 mlx5e_select_queue(struct net_device *dev, struct sk_buff *skb,
+#ifdef HAVE_SELECT_QUEUE_FALLBACK_T
 		       void *accel_priv, select_queue_fallback_t fallback)
+#else
+		       select_queue void *accel_priv)
+#endif
+#else /* NDO_SELECT_QUEUE_HAS_ACCEL_PRIV || HAVE_SELECT_QUEUE_FALLBACK_T */
+u16 mlx5e_select_queue(struct net_device *dev, struct sk_buff *skb)
+#endif
 {
 	struct mlx5e_priv *priv = netdev_priv(dev);
 	int channel_ix = fallback(dev, skb);
@@ -91,7 +103,11 @@ static inline u16 mlx5e_get_inline_hdr_size(struct mlx5e_sq *sq,
 
 	/* inline improves latency but hearts message rate */
 	/* TODO: review if !skb->sk is ok indication for packet forwarding */
+#ifdef HAVE_SK_BUFF_XMIT_MORE
 	if ((sq->cc != sq->pc) || skb->xmit_more || !skb->sk/*fwd pkt*/)
+#else
+	if ((sq->cc != sq->pc) || !skb->sk/*fwd pkt*/)
+#endif
 		return MLX5E_MIN_INLINE;
 
 	if (!skb_shinfo(skb)->nr_frags && (skb_headlen(skb) < MLX5E_MAX_INLINE))
@@ -108,7 +124,11 @@ static inline void mlx5e_insert_vlan(void *start, struct sk_buff *skb, u16 ihs)
 
 	skb_copy_from_linear_data(skb, vhdr, cpy1_sz);
 	skb_pull_inline(skb, cpy1_sz);
+#ifdef HAVE_SK_BUFF_VLAN_PROTO
 	vhdr->h_vlan_proto = skb->vlan_proto;
+#else
+	vhdr->h_vlan_proto = htons(ETH_P_8021Q);
+#endif
 	vhdr->h_vlan_TCI = cpu_to_be16(skb_vlan_tag_get(skb));
 	skb_copy_from_linear_data(skb, &vhdr->h_vlan_encapsulated_proto,
 				  cpy2_sz);
@@ -231,7 +251,9 @@ static netdev_tx_t mlx5e_sq_xmit(struct mlx5e_sq *sq, struct sk_buff *skb)
 		sq->stats.stopped++;
 	}
 
+#ifdef HAVE_SK_BUFF_XMIT_MORE
 	if (!skb->xmit_more || netif_xmit_stopped(sq->txq))
+#endif
 		mlx5e_tx_notify_hw(sq, wqe);
 
 	sq->stats.packets++;
diff --git a/drivers/net/ethernet/mellanox/mlx5/core/main.c b/drivers/net/ethernet/mellanox/mlx5/core/main.c
index xxxxxxx..xxxxxxx xxxxxx
--- a/drivers/net/ethernet/mellanox/mlx5/core/main.c
+++ b/drivers/net/ethernet/mellanox/mlx5/core/main.c
@@ -241,6 +241,9 @@ static int mlx5_enable_msix(struct mlx5_core_dev *dev)
 	struct mlx5_eq_table *table = &dev->priv.eq_table;
 	int num_eqs = 1 << MLX5_CAP_GEN(dev, log_max_eq);
 	int nvec;
+#ifndef HAVE_PCI_ENABLE_MSIX_RANGE
+	int err;
+#endif
 	int i;
 
 	nvec = MLX5_CAP_GEN(dev, num_ports) * num_online_cpus() +
@@ -256,12 +259,26 @@ static int mlx5_enable_msix(struct mlx5_core_dev *dev)
 	for (i = 0; i < nvec; i++)
 		table->msix_arr[i].entry = i;
 
+#ifdef HAVE_PCI_ENABLE_MSIX_RANGE
 	nvec = pci_enable_msix_range(dev->pdev, table->msix_arr,
 				     MLX5_EQ_VEC_COMP_BASE + 1, nvec);
 	if (nvec < 0)
 		return nvec;
 
 	table->num_comp_vectors = nvec - MLX5_EQ_VEC_COMP_BASE;
+#else
+retry:
+	table->num_comp_vectors = nvec - MLX5_EQ_VEC_COMP_BASE;
+	err = pci_enable_msix(dev->pdev, table->msix_arr, nvec);
+	if (err <= 0) {
+		return err;
+	} else if (err > 2) {
+		nvec = err;
+		goto retry;
+	}
+
+	mlx5_core_dbg(dev, "received %d MSI vectors out of %d requested\n", err, nvec);
+#endif
 
 	return 0;
 }
@@ -555,7 +572,9 @@ static void mlx5_set_comp_eqs_affinity(struct mlx5_core_dev *dev)
 			mlx5_core_warn(dev,
 				       "zalloc_cpumask_var failed for comp eq: %d",
 				       eq->index);
+#ifdef CONFIG_CPUMASK_OFFSTACK
 			eq->affinity_mask = NULL;
+#endif
 			return;
 		}
 
@@ -565,7 +584,9 @@ static void mlx5_set_comp_eqs_affinity(struct mlx5_core_dev *dev)
 					  eq->affinity_mask)) {
 			mlx5_core_warn(dev, "irq_set_affinity_hint failed");
 			free_cpumask_var(eq->affinity_mask);
+#ifdef CONFIG_CPUMASK_OFFSTACK
 			eq->affinity_mask = NULL;
+#endif
 			return;
 		}
 	}
@@ -578,8 +599,10 @@ static void mlx5_clear_comp_eqs_affinity(struct mlx5_core_dev *dev)
 	struct mlx5_eq *eq, *n;
 
 	list_for_each_entry_safe(eq, n, &table->comp_eqs_list, list) {
+#ifdef CONFIG_CPUMASK_OFFSTACK
 		if (!eq->affinity_mask)
 			continue;
+#endif
 
 		free_cpumask_var(eq->affinity_mask);
 		irq_set_affinity_hint(table->msix_arr[eq->irqn].vector, NULL);
diff --git a/include/linux/compat-3.5.h b/include/linux/compat-3.5.h
index xxxxxxx..xxxxxxx xxxxxx
--- a/include/linux/compat-3.5.h
+++ b/include/linux/compat-3.5.h
@@ -217,6 +217,20 @@ static inline bool ether_addr_equal(const u8 *addr1, const u8 *addr2)
 	return !compare_ether_addr(addr1, addr2);
 }
 
+#include <linux/skbuff.h>
+
+#define skb_end_offset LINUX_BACKPORT(skb_end_offset)
+#ifdef NET_SKBUFF_DATA_USES_OFFSET
+static inline unsigned int skb_end_offset(const struct sk_buff *skb)
+{
+	return skb->end;
+}
+#else
+static inline unsigned int skb_end_offset(const struct sk_buff *skb)
+{
+	return skb->end - skb->head;
+}
+#endif
 #endif /* (LINUX_VERSION_CODE < KERNEL_VERSION(3,5,0)) */
 
 #endif /* LINUX_3_5_COMPAT_H */
diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index xxxxxxx..xxxxxxx xxxxxx
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -596,8 +596,13 @@ struct mlx5_cmd_work_ent {
 	int			page_queue;
 	u8			status;
 	u8			token;
+#ifdef HAVE_KTIME_GET_NS
 	u64			ts1;
 	u64			ts2;
+#else
+	struct timespec ts1;
+	struct timespec ts2;
+#endif
 	u16			op;
 };
 
